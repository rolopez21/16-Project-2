{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from path import Path\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "from newsapi import NewsApiClient\n",
    "#from ibm_watson import ToneAnalyzerV3\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching latest News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from newsapi import NewsApiClient\n",
    "from newsapi.newsapi_client import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "api_key = os.getenv('NEWS_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change date and thicker if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Roger.Lopez\\source\\repos\\16-Project-2\\notebooks\\news_sentiment_analysis.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roger.Lopez/source/repos/16-Project-2/notebooks/news_sentiment_analysis.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m start_date \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2019-10-12\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roger.Lopez/source/repos/16-Project-2/notebooks/news_sentiment_analysis.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m end_date \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2019-11-11\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Roger.Lopez/source/repos/16-Project-2/notebooks/news_sentiment_analysis.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m news \u001b[39m=\u001b[39m newsapi\u001b[39m.\u001b[39;49mget_everything(q\u001b[39m=\u001b[39;49mthicker, language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m, from_param\u001b[39m=\u001b[39;49m start_date, to\u001b[39m=\u001b[39;49m end_date ,sort_by\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelevancy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roger.Lopez/source/repos/16-Project-2/notebooks/news_sentiment_analysis.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m news[\u001b[39m\"\u001b[39m\u001b[39mtotalResults\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\newsapi\\newsapi_client.py:322\u001b[0m, in \u001b[0;36mNewsApiClient.get_everything\u001b[1;34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpage param should be an int\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    321\u001b[0m \u001b[39m# Send Request\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_method\u001b[39m.\u001b[39;49mget(const\u001b[39m.\u001b[39;49mEVERYTHING_URL, auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth, timeout\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, params\u001b[39m=\u001b[39;49mpayload)\n\u001b[0;32m    324\u001b[0m \u001b[39m# Check Status of Request\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m requests\u001b[39m.\u001b[39mcodes\u001b[39m.\u001b[39mok:\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    396\u001b[0m         conn\u001b[39m.\u001b[39mrequest_chunked(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (six\u001b[39m.\u001b[39mensure_str(k\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m headers):\n\u001b[0;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1280\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1281\u001b[0m     \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1323\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1320\u001b[0m     encode_chunked \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[39mfor\u001b[39;00m hdr, value \u001b[39min\u001b[39;00m headers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mputheader(hdr, value)\n\u001b[0;32m   1324\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1325\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:224\u001b[0m, in \u001b[0;36mHTTPConnection.putheader\u001b[1;34m(self, header, *values)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(v, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m v \u001b[39m==\u001b[39m SKIP_HEADER \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values):\n\u001b[1;32m--> 224\u001b[0m     _HTTPConnection\u001b[39m.\u001b[39;49mputheader(\u001b[39mself\u001b[39;49m, header, \u001b[39m*\u001b[39;49mvalues)\n\u001b[0;32m    225\u001b[0m \u001b[39melif\u001b[39;00m six\u001b[39m.\u001b[39mensure_str(header\u001b[39m.\u001b[39mlower()) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m SKIPPABLE_HEADERS:\n\u001b[0;32m    226\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39murllib3.util.SKIP_HEADER only supports \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mtitle, \u001b[39msorted\u001b[39m(SKIPPABLE_HEADERS))),)\n\u001b[0;32m    229\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roger.Lopez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1259\u001b[0m, in \u001b[0;36mHTTPConnection.putheader\u001b[1;34m(self, header, *values)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(one_value, \u001b[39mint\u001b[39m):\n\u001b[0;32m   1257\u001b[0m         values[i] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(one_value)\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[39mif\u001b[39;00m _is_illegal_header_value(values[i]):\n\u001b[0;32m   1260\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid header value \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (values[i],))\n\u001b[0;32m   1262\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(values)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Fetch the news articles\n",
    "thicker = \"Valero\"\n",
    "start_date = \"2019-10-12\"\n",
    "end_date = \"2019-11-11\"\n",
    "news = newsapi.get_everything(q=thicker, language=\"en\", from_param= start_date, to= end_date ,sort_by=\"relevancy\")\n",
    "news[\"totalResults\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuction to get sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(text, date, source, url):\n",
    "    sentiment_scores = {}\n",
    "\n",
    "    # Sentiment scoring with VADER\n",
    "    text_sentiment = analyzer.polarity_scores(text)\n",
    "    sentiment_scores[\"date\"] = date\n",
    "    sentiment_scores[\"text\"] = text\n",
    "    sentiment_scores[\"source\"] = source\n",
    "    sentiment_scores[\"url\"] = url\n",
    "    sentiment_scores[\"compound\"] = text_sentiment[\"compound\"]\n",
    "    sentiment_scores[\"pos\"] = text_sentiment[\"pos\"]\n",
    "    sentiment_scores[\"neu\"] = text_sentiment[\"neu\"]\n",
    "    sentiment_scores[\"neg\"] = text_sentiment[\"neg\"]\n",
    "    if text_sentiment[\"compound\"] >= 0.05:  # Positive\n",
    "        sentiment_scores[\"normalized\"] = 1\n",
    "    elif text_sentiment[\"compound\"] <= -0.05:  # Negative\n",
    "        sentiment_scores[\"normalized\"] = -1\n",
    "    else:\n",
    "        sentiment_scores[\"normalized\"] = 0  # Neutral\n",
    "\n",
    "    return sentiment_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create for loop for DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>normalized</th>\n",
       "      <th>pos</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>The Next Web</td>\n",
       "      <td>IBM today announced the 2019 Call for Code gra...</td>\n",
       "      <td>https://thenextweb.com/artificial-intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Wtap.com</td>\n",
       "      <td>HOUSTON (KTRK/CNN) - Police in Houston are sea...</td>\n",
       "      <td>https://www.wtap.com/content/news/Texas-woman-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.741</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>Yahoo.com</td>\n",
       "      <td>Some say volatility, rather than debt, is the ...</td>\n",
       "      <td>https://finance.yahoo.com/news/valero-energy-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-15</th>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Si.com</td>\n",
       "      <td>Este fin de semana hubo actividad de la Fecha ...</td>\n",
       "      <td>https://www.si.com/soccer/2019/10/15/marchesin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-23</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115</td>\n",
       "      <td>Si.com</td>\n",
       "      <td>Inter got their Champions League campaign back...</td>\n",
       "      <td>https://www.si.com/soccer/2019/10/23/inter-2-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound    neg    neu  normalized    pos        source  \\\n",
       "date                                                                  \n",
       "2019-10-13    0.8402  0.000  0.795           1  0.205  The Next Web   \n",
       "2019-10-13   -0.7430  0.161  0.839          -1  0.000      Wtap.com   \n",
       "2019-10-13   -0.0772  0.151  0.741          -1  0.108     Yahoo.com   \n",
       "2019-10-15   -0.2960  0.045  0.955          -1  0.000        Si.com   \n",
       "2019-10-23    0.4939  0.048  0.837           1  0.115        Si.com   \n",
       "\n",
       "                                                         text  \\\n",
       "date                                                            \n",
       "2019-10-13  IBM today announced the 2019 Call for Code gra...   \n",
       "2019-10-13  HOUSTON (KTRK/CNN) - Police in Houston are sea...   \n",
       "2019-10-13  Some say volatility, rather than debt, is the ...   \n",
       "2019-10-15  Este fin de semana hubo actividad de la Fecha ...   \n",
       "2019-10-23  Inter got their Champions League campaign back...   \n",
       "\n",
       "                                                          url  \n",
       "date                                                           \n",
       "2019-10-13  https://thenextweb.com/artificial-intelligence...  \n",
       "2019-10-13  https://www.wtap.com/content/news/Texas-woman-...  \n",
       "2019-10-13  https://finance.yahoo.com/news/valero-energy-n...  \n",
       "2019-10-15  https://www.si.com/soccer/2019/10/15/marchesin...  \n",
       "2019-10-23  https://www.si.com/soccer/2019/10/23/inter-2-0...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_data = []\n",
    "\n",
    "# Loop through all the news articles\n",
    "for article in news[\"articles\"]:\n",
    "    try:\n",
    "        # Get sentiment scoring using the get_sentiment_score() function\n",
    "        sentiments_data.append(\n",
    "            get_sentiment_scores(\n",
    "                article[\"content\"],\n",
    "                article[\"publishedAt\"][:10],\n",
    "                article[\"source\"][\"name\"],\n",
    "                article[\"url\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "news_df = pd.DataFrame(sentiments_data)\n",
    "news_df = news_df.sort_values(by=\"date\")\n",
    "news_df.set_index(\"date\", inplace=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>normalized</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.116050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.453504</td>\n",
       "      <td>0.055072</td>\n",
       "      <td>0.085796</td>\n",
       "      <td>0.82717</td>\n",
       "      <td>0.078074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.743000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.410550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.740650</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.883400</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound        neg        neu  normalized        pos\n",
       "count  20.000000  20.000000  20.000000    20.00000  20.000000\n",
       "mean    0.336280   0.040750   0.843200     0.50000   0.116050\n",
       "std     0.453504   0.055072   0.085796     0.82717   0.078074\n",
       "min    -0.743000   0.000000   0.699000    -1.00000   0.000000\n",
       "25%     0.000000   0.000000   0.795750     0.00000   0.057250\n",
       "50%     0.410550   0.000000   0.837500     1.00000   0.138000\n",
       "75%     0.740650   0.062000   0.869500     1.00000   0.167500\n",
       "max     0.883400   0.161000   1.000000     1.00000   0.260000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rolop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \n",
    "    #create list\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #covert to lowercase\n",
    "    text = [word.lower() for word in text]\n",
    "    \n",
    "    #remove punctuation\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    text = [regex.sub('', word) for word in text]\n",
    "    \n",
    "    # Remove the stop words\n",
    "    sw = set(stopwords.words('english'))\n",
    "    \n",
    "    # Lemmatize Words into root words\n",
    "    lem = WordNetLemmatizer() #root words\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = [word for word in text if word not in sw]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'raw_article'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-dfdba940451a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_article\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'raw_article'"
     ]
    }
   ],
   "source": [
    "news_df.raw_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_article</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM today announced the 2019 Call for Code gra...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>[ibm, today, announced, , call, code, grand, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image source: The Motley Fool.\\r\\nValero Energ...</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.848</td>\n",
       "      <td>[image, source, , motley, fool, , valero, ener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valero Energy(NYSE:VLO) is one of the largest ...</td>\n",
       "      <td>0.4599</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.802</td>\n",
       "      <td>[valero, energy, , nyse, , vlo, , one, largest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Courtesy: Houston Chronicle - Image: Corpus Ch...</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>[courtesy, , houston, chronicle, , image, , co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's how our experts see the bowl matchups a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[expert, see, bowl, matchup, week, , , check, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_article  compound  positive  \\\n",
       "0  IBM today announced the 2019 Call for Code gra...    0.8402     0.205   \n",
       "1  Image source: The Motley Fool.\\r\\nValero Energ...   -0.2023     0.064   \n",
       "2  Valero Energy(NYSE:VLO) is one of the largest ...    0.4599     0.136   \n",
       "3  Courtesy: Houston Chronicle - Image: Corpus Ch...    0.6908     0.153   \n",
       "4  Here's how our experts see the bowl matchups a...    0.0000     0.000   \n",
       "\n",
       "   negative  neutral                                              Token  \n",
       "0     0.000    0.795  [ibm, today, announced, , call, code, grand, p...  \n",
       "1     0.088    0.848  [image, source, , motley, fool, , valero, ener...  \n",
       "2     0.061    0.802  [valero, energy, , nyse, , vlo, , one, largest...  \n",
       "3     0.000    0.847  [courtesy, , houston, chronicle, , image, , co...  \n",
       "4     0.000    1.000  [expert, see, bowl, matchup, week, , , check, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_token = []\n",
    "[news_token.append(tokenizer(text)) for text in news_df.raw_article]   \n",
    "news_df['Token'] = news_token\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4b713e85380f88a00777cdcdc0b317b22afcd9ce36339ad381340bf82814c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
